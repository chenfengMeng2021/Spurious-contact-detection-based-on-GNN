{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31027d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.sparse import csr_matrix,load_npz, coo_matrix, linalg, identity, hstack, lil_array\n",
    "from tqdm import tqdm\n",
    "from math import log,exp,sqrt\n",
    "import logging\n",
    "import copy\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.sparse import csr_matrix, linalg, identity, lil_matrix, hstack\n",
    "import networkx as nx\n",
    "\n",
    "contig_file = \"../data/corrected_contig_info_combine.csv\"\n",
    "raw_contact_file = \"../data/raw_contact_matrix.npz\"\n",
    "path = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348a2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd05369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e240f356",
   "metadata": {},
   "source": [
    "## Auxiliary Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76fee37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normcc(df):\n",
    "\n",
    "    df['log_site'] = np.log(df['site'])\n",
    "    df['log_length'] = np.log(df['length'])\n",
    "    df['log_covcc'] = np.log(df['covcc'])\n",
    "    \n",
    "    exog = df[['log_site', 'log_length', 'log_covcc']]\n",
    "    endog = df[\"signal\"]\n",
    "    exog = sm.add_constant(exog)\n",
    "    glm_nb = sm.GLM(endog, exog, family=sm.families.NegativeBinomial(alpha=1))\n",
    "    res = glm_nb.fit(method=\"lbfgs\")\n",
    "\n",
    "    return res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdfac3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rows_excluding_diagonal(sparse_mat):\n",
    "    sparse_mat = csr_matrix(sparse_mat)\n",
    "    # Get the shape of the matrix\n",
    "    n_rows, n_cols = sparse_mat.shape\n",
    "\n",
    "    # Initialize an array to store the row sums\n",
    "    row_sums_excluding_diagonal = np.zeros(n_rows)\n",
    "\n",
    "    # Iterate over each row\n",
    "    for i in range(n_rows):\n",
    "        # Get the start and end indices of the data in the current row\n",
    "        start_index = sparse_mat.indptr[i]\n",
    "        end_index = sparse_mat.indptr[i + 1]\n",
    "\n",
    "        # Get the column indices and data for the current row\n",
    "        row_indices = sparse_mat.indices[start_index:end_index]\n",
    "        row_data = sparse_mat.data[start_index:end_index]\n",
    "\n",
    "        # Sum the elements excluding the diagonal element\n",
    "        row_sum = sum(row_data[j] for j in range(len(row_data)) if row_indices[j] != i)\n",
    "\n",
    "        # Store the sum in the result array\n",
    "        row_sums_excluding_diagonal[i] = row_sum\n",
    "\n",
    "    return row_sums_excluding_diagonal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c4b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizemap(norm_params, metadata, contact_matrix):\n",
    "    contact_matrix = contact_matrix.tocoo()\n",
    "    norm_data = []\n",
    "    mu_vector = []\n",
    "    for site, length, covcc in zip(metadata[\"site\"], metadata['length'], metadata['covcc']):\n",
    "        mu_vector.append(np.exp(log(site) * norm_params['log_site'] +\n",
    "                    log(length) * norm_params['log_length'] +\n",
    "                    log(covcc) * norm_params['log_covcc'] +\n",
    "                    norm_params['const']))\n",
    "        \n",
    "    scale = np.max(mu_vector)\n",
    "    for idx, value in enumerate(contact_matrix.data):\n",
    "        i, j = contact_matrix.row[idx], contact_matrix.col[idx]\n",
    "        norm_value = scale * value / np.sqrt(mu_vector[i] * mu_vector[j])\n",
    "        norm_data.append(norm_value)\n",
    "    \n",
    "    return coo_matrix((norm_data, (contact_matrix.row, contact_matrix.col)), shape=contact_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e287ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_true_contact(matrix, metadata, self_loop):\n",
    "    # calculate the true connection for local similarity\n",
    "    matrix = coo_matrix(matrix)\n",
    "    rows = matrix.row\n",
    "    cols = matrix.col\n",
    "    \n",
    "    index = (rows <= cols)\n",
    "    rows = rows[index]\n",
    "    cols = cols[index]\n",
    "    \n",
    "    true_positive = set()\n",
    "    for i in tqdm(range(len(rows))):\n",
    "        row = rows[i]\n",
    "        col = cols[i]\n",
    "        if row == col and not self_loop: # if self-loop is False and row = col, then jump over rest code in the cycle, which means row = col point won't be added into the True positive, thus, self-loop is not included. and self-loop false relised.  \n",
    "            continue\n",
    "        if metadata[\"True_identity\"][row] != metadata[\"True_identity\"][col]:\n",
    "            true_positive.add((row,col))\n",
    "    return true_positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b51e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate AUDRC\n",
    "def calculate_audrc(scores):\n",
    "    scores.sort(key=lambda x: x[2], reverse=True)\n",
    "    true_positive_count = sum(1 for _, _, _, is_tp in scores if is_tp)\n",
    "    spurious_contact_count = len(scores) - true_positive_count\n",
    "    tpr = []\n",
    "    discard_proportion = []\n",
    "    thresholds = np.percentile([x[2] for x in scores], np.arange(0, 105, 5))\n",
    "    for threshold in thresholds:\n",
    "        tp_cumsum = sum(1 for _, _, score, is_tp in scores if score >= threshold and is_tp)\n",
    "        spurious_cumsum = sum(1 for _, _, score, is_tp in scores if score < threshold and not is_tp)\n",
    "        tpr.append(tp_cumsum / true_positive_count)\n",
    "        discard_proportion.append(spurious_cumsum / spurious_contact_count)\n",
    "    audrc = auc(discard_proportion, tpr)\n",
    "    return audrc, tpr, discard_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c54b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "## utils for global similarity\n",
    "def nodes_to_indexes(G: nx.Graph):\n",
    "    \"\"\"Node Label - Index encoder\n",
    "\n",
    "    Associate, for each node label, and index starting from 0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G: nx.Graph :\n",
    "        the graph from which you want the node-to-index mapping\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[Any, int]: the encoding Node Label - Index dictionary\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The method `Graph.nodes` return the nodes in the exactly same order, and\n",
    "    the first node (at index 0) represent the index 0 in the Adjacency Matrix\n",
    "    obtained with the method `Graph.to_adjacency_matrix` or\n",
    "    `Graph.to_numpy_array`.\n",
    "    \"\"\"\n",
    "    return {node_name: index for index, node_name in enumerate(G.nodes)}\n",
    "\n",
    "def to_adjacency_matrix(G: nx.Graph,\n",
    "                        sparse: bool = True):\n",
    "    \"\"\"Convert a ginven Graph in to its Adjacency Matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G: nx.Graph :\n",
    "        input Graph (a networkx Graph)\n",
    "    sparse: bool:\n",
    "        if True, return the Adjacency Matrix in sparse format,\n",
    "        otherwise in full format.\n",
    "         (Default value = True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    csc_matrix | np.ndarray: the Adjacency Matrix\n",
    "    \"\"\"\n",
    "    # TODO: ricontrollare se i pesi servono\n",
    "    return nx.adjacency_matrix(\n",
    "        G, weight=None) if sparse else nx.to_numpy_array(G, weight=None)\n",
    "\n",
    "def only_unconnected(graph: nx.Graph, sim_matrix: lil_matrix):\n",
    "    \"\"\"Filter the given matrix and return only previously unconnected\n",
    "    nodes \"similarity\" values\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph: nx.Graph :\n",
    "        input graph\n",
    "    sim_matrix: csr_matrix :\n",
    "        similarity matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sim_matrix: csr_matrix : the similarity matrix without the previously\n",
    "    connected nodes similarity\n",
    "    \"\"\"\n",
    "    node_idexies_map = nodes_to_indexes(graph)\n",
    "\n",
    "    for x, y in graph.edges():\n",
    "        sim_matrix[node_idexies_map[x], node_idexies_map[y]] = 0\n",
    "\n",
    "    sim_matrix = sim_matrix.tocsr()\n",
    "    sim_matrix.eliminate_zeros()\n",
    "\n",
    "    return sim_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21b07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_prediction_rwr(G: nx.Graph,\n",
    "                        c: int = 0.05,\n",
    "                        max_iters: int = 10) -> csr_matrix:\n",
    "    \"\"\"Compute the Random Walk with Restart Algorithm.\n",
    "\n",
    "    The similarity between two nodes is defined as:\n",
    "\n",
    "    .. math::\n",
    "        S(x, y) = q_{xy} + q_{yx}\n",
    "\n",
    "    where \\\\(q_x\\\\) is defined as \\\\( (1-\\\\alpha) (I - \\\\alpha P^T)^{-1} e_x\\\\)\n",
    "    and \\\\(e_x\\\\) is the seed vector of length \\\\(|V|\\\\).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G: nx.Graph :\n",
    "        input Graph (a networkx Graph)\n",
    "    c: int :\n",
    "        TODO\n",
    "         (Default value = 0.05)\n",
    "    max_iters: int :\n",
    "        max number of iteration for the algorithm convergence\n",
    "         (Default value = 10)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    similarity_matrix: csr_matrix : the Similarity Matrix (in sparse format)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Let \\\\(\\\\alpha\\\\) be a probability that a random walker\n",
    "    iteratively moves to an arbitrary neighbor and returns to the same\n",
    "    starting vertex with probability \\\\( (1 - \\\\alpha )\\\\).\n",
    "    Consider \\\\(q_{xy}\\\\) to be the probability that a random walker\n",
    "    who starts walking from vertex x and located at the vertex y in steady-state.\n",
    "\n",
    "    The seed vector \\\\(e_x\\\\) consists of zeros for all components except the\n",
    "    elements \\\\(x\\\\) itself.\n",
    "\n",
    "    The transition matrix \\\\(P\\\\) can be expressed as\n",
    "\n",
    "    .. math::\n",
    "        P_{xy} = \\\\begin{cases}\n",
    "                \\\\frac{1}{k_x} & \\\\text{if } x \\\\text{ and } y \\\\text{ are connected,} \\\\\\\\\n",
    "                0 & \\\\text{otherwise.}\n",
    "            \\\\end{cases}\n",
    "    \"\"\"\n",
    "\n",
    "    def random_walk_with_restart(e: lil_array,\n",
    "                                 W_normalized: csr_matrix,\n",
    "                                 c: int = 0.05,\n",
    "                                 max_iters: int = 100) -> lil_array:\n",
    "        \"\"\"Generates the probability vector\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        e: lil_array :\n",
    "            input probability vector\n",
    "        W_normalized: csr_matrix :\n",
    "            TODO\n",
    "        c: int :\n",
    "            TODO\n",
    "             (Default value = 0.05)\n",
    "        max_iters: int :\n",
    "            max number of iteration for the algorithm convergence\n",
    "             (Default value = 100)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        e: lil_array : the updated probability vector\n",
    "        \"\"\"\n",
    "        # Initialize the current probability vector to the initial one and the error to 1\n",
    "        old_e = e\n",
    "        err = 1.\n",
    "\n",
    "        # Perform the random walk with restart until the maximum number\n",
    "        # of iterations is reached or the error becomes less than 1e-6\n",
    "        for _ in range(max_iters):\n",
    "            e = (c * (W_normalized @ old_e)) + ((1 - c) * e)\n",
    "            err = linalg.norm(e - old_e, 1)\n",
    "            if err <= 1e-6:\n",
    "                break\n",
    "            old_e = e\n",
    "\n",
    "        # Return the current probability vector\n",
    "        return e\n",
    "\n",
    "    # Convert the graph G into an adjacency matrix A\n",
    "    A = to_adjacency_matrix(G)\n",
    "\n",
    "    # Extract the number of nodes of matrix A\n",
    "    m = A.shape[0]\n",
    "\n",
    "    # Initialize the diagonal matrix D as a sparse lil_matrix\n",
    "    D = lil_matrix(A.shape)\n",
    "\n",
    "    # Create a map that associates each node with a row index in matrix A\n",
    "    nodes_to_indexes_map = nodes_to_indexes(G)\n",
    "\n",
    "    # Build the diagonal matrix D so that the elements on the diagonal\n",
    "    # are equal to the degree of the corresponding node\n",
    "    for node in G.nodes():\n",
    "        D[nodes_to_indexes_map[node],\n",
    "          nodes_to_indexes_map[node]] = G.degree[node]\n",
    "\n",
    "    # Convert the diagonal matrix D into csc_matrix format\n",
    "    D = D.tocsc()\n",
    "\n",
    "    try:\n",
    "        # Build the normalized transition matrix W_normalized\n",
    "        W_normalized = linalg.inv(D) @ A.tocsc()\n",
    "    except RuntimeError as e:\n",
    "        print('Possible presence of singleton nodes in the graph G')\n",
    "        print(e)\n",
    "        exit(1)\n",
    "\n",
    "    # Initialize an matrix to hold the similarities between node pairs\n",
    "    # We put an initial column made of Zeros so we can use the hstack\n",
    "    # method later on and keep the code more clean\n",
    "    similarity_matrix = csr_matrix((m, 1))\n",
    "\n",
    "    # For each node i, create a probability vector and perform the\n",
    "    # random walk with restart starting from that node\n",
    "    for i in range(m):\n",
    "        e = lil_array((m, 1))\n",
    "        e[i, 0] = 1\n",
    "        # Concatenate the similarity vectors into a similarity matrix\n",
    "        # The use of hstack allows the lil_array returned from the\n",
    "        # random walk function to be transposed and added to the\n",
    "        # similarity matrix as a new column in just one line of code\n",
    "        similarity_matrix = hstack([\n",
    "            similarity_matrix,\n",
    "            random_walk_with_restart(e=e,\n",
    "                                     W_normalized=W_normalized,\n",
    "                                     c=c,\n",
    "                                     max_iters=max_iters)\n",
    "        ])\n",
    "\n",
    "    # Return the similarity matrix and remove the fisrt column\n",
    "    # In order to keep the results consistent without the added column of zeros at the beginning\n",
    "    return only_unconnected(G, csr_matrix(similarity_matrix)[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7645d933",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7accd394",
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_matrix = load_npz(raw_contact_file).tocoo()\n",
    "meta_data = pd.read_csv(contig_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a7fa053",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['name', 'site', 'length', 'coverage', 'covcc', \"True_identity\"]\n",
    "meta_data.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "996c403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the row sums excluding the diagonal\n",
    "signal = sum_rows_excluding_diagonal(contact_matrix)\n",
    "meta_data[\"signal\"] = signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d876c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the coffecient\n",
    "coffecient = normcc(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6870a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_contact_matrix = normalizemap(coffecient, meta_data, contact_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92ab3101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562066/562066 [00:03<00:00, 156237.20it/s]\n"
     ]
    }
   ],
   "source": [
    "## calculate the valid contacts in the map\n",
    "true_contact = calculate_true_contact(contact_matrix, meta_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f55d059e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  44,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    9,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,  194, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   11,    0,    0],\n",
       "       [   0,    0,    0, ...,    0, 3787,    0],\n",
       "       [   0,    0,    0, ...,    0,    0, 1787]], dtype=uint32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix = contact_matrix.toarray()\n",
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e205fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph from the adjacency matrix\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add edges with weights to the graph\n",
    "for i in range(len(adj_matrix)):\n",
    "    for j in range(len(adj_matrix[i])):\n",
    "        weight = adj_matrix[i][j]\n",
    "        if weight != 0:\n",
    "            G.add_edge(i, j, weight=weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymatrix = link_prediction_rwr(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8793f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
